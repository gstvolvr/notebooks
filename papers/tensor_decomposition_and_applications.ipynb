{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Tensor Decomposition and Applications](https://www.jstor.org/stable/25662308?seq=1#metadata_info_tab_contents)\n",
    "A tensor is a multidimensional N-way array. \n",
    "\n",
    "Two tensor decomposition methods can be considered higher order extensions of the matrix singular value decomposition (`SVD`): CANDECOMP / PARAFAC (`CP`) decomposes a tensor as a sum of rank one tensors. `Tucker decomposition` is a higher order form of principal component analysis. \n",
    "\n",
    "A first order tensor is a vector.<br>\n",
    "A second order tensor is a matrix. <br>\n",
    "Tensors of order three or higher are called higher-order tensors. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (2, 3, 3)\n",
      "tensor: \n",
      "[[[1 0 0]\n",
      "  [0 2 0]\n",
      "  [0 0 3]]\n",
      "\n",
      " [[4 0 0]\n",
      "  [0 5 0]\n",
      "  [0 0 6]]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tensor = tf.linalg.diag([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"shape: \", tensor.shape)\n",
    "sess = tf.Session()\n",
    "print(\"tensor: \")\n",
    "print(sess.run(tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notation\n",
    "The `order` of a tensor is the number of dimensions, also known as modes. Vectors are denoted by boldface lowercase letters, matrices are denoted boldface by uppercase letters, and tensors are denoted boldface Euler script letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order:  3\n"
     ]
    }
   ],
   "source": [
    "print(\"order: \", sess.run(tf.rank(tensor)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher-order analogue of matrix rows and columns, are known as `fibers`. A matrix column is a <strong>mode-1 fiber</strong> and a matrix row is a <strong>mode-2 fiber</strong>. When extracted from a tensor, fibers are assumed to be oriented as column vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column vector:  [0 0 3]\n",
      "row vector:  [0 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"column vector: \", sess.run(tensor[0, :, 2]))\n",
    "print(\"row vector: \", sess.run(tensor[0, 1, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`slices` are two dimensional sections of a tensor, defined by fixing all but two indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice: \n",
      "[[1 0 0]\n",
      " [0 2 0]\n",
      " [0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "print(\"slice: \")\n",
    "print(sess.run(tensor[0, :, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `norm` of a tensor, is the square root sum of all of the squares of all of it's elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm:  9.539392\n"
     ]
    }
   ],
   "source": [
    "print(\"norm: \", sess.run(tf.norm(tf.dtypes.cast(tensor, dtype=tf.float32))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `inner product` of two same sized tensors $\\mathscr{X}, \\mathscr{Y} \\in{\\mathbb{R}^{I_1 x I_2 x ... x I_N}}$ is the sum of their product entries\n",
    "\n",
    "$$<\\mathscr{X}, \\mathscr{Y}> = \\sum_{i_1=1}^{I_1} \\sum_{i_2=1}^{I_2} ... \\sum_{i_N=1}^{I_N} x_{i_1 i_2 ... i_N} y_{i_1 i_2 ... i_N} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inner product:  91\n"
     ]
    }
   ],
   "source": [
    "print(\"inner product: \", sess.run(tf.reduce_sum(tf.multiply(tensor, tensor), keep_dims=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank-one tensors\n",
    "An N-way tensor $\\mathscr{X} \\in{\\mathbb{R}^{I_1 x I_2 x ... x I_N}}$ is `rank one` if it can be written as the `outer product` of N vectors\n",
    "\n",
    "$$ \\mathscr{X} = \\textbf{a}^{(1)} \\circ ~\\textbf{a}^{(2)} \\circ ~...~ \\circ ~\\textbf{a}^{(N)}$$\n",
    "\n",
    "Where $\\circ$ is the vector outer product, that is, each element of the tensor is the product of the corresponding elements of the vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symmetry and tensors\n",
    "A tensor is called `cubical` or `symmetric` when every mode is the same size, i.e. $\\mathscr{X} \\in{\\mathbb{R}^{I x I x ... x I}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matricization: transforming a tensor into a matrix\n",
    "The process of re-ordering an N-way tensor into a matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Kronecker, Khatri-Rao, and Hadamard Products\n",
    "The `Kronecker product` of matrices looks like $A \\in \\mathbb{R}^{IxJ}$ and $B \\in \\mathbb{R}^{KxL}$ is defined by:\n",
    "\n",
    "$A\\otimes B = \\begin{bmatrix} \n",
    "a_{11}B & a_{12}B & ... & a_{1J}B \\\\\n",
    "a_{21}B & a_{22}B & ... & a_{2J}B \\\\\n",
    "... \\\\\n",
    "a_{I1}B & a_{I2}B & ... & a_{IJ}B \\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "<br>\n",
    "$A \\otimes B = [a_1 \\otimes b_1  ~a_1 \\otimes b_2 ...  ~a_J \\otimes b_{L-1} ~a_J \\otimes b_L ]$\n",
    "\n",
    "The resulting matrix is of size $(IJ) \\times (KL)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Khatri-Rao product` is the matching columnwise `Kronecker product`. \n",
    "\n",
    "$ A \\odot B = [a_1 \\otimes b_1  ~a_2 \\otimes b_2 ...  ~a_K \\otimes b_K ]$\n",
    "\n",
    "if $\\textbf{a}$ and $\\textbf{b}$ are vectors, then the two are the same\n",
    "$\\textbf{a} \\otimes \\textbf{b} = \\textbf{a} \\odot \\textbf{b} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Decomposition\n",
    "\n",
    "### CP Decomposition\n",
    "AKA (CANDECOMP/PARAFAC)\n",
    "\n",
    "It's a higher order version of `SVD`. It factorizes a tensor into a sum of component rank-one tensors. For example, given a third order tensor $\\mathscr{X} \\in{\\mathbb{R}^{I x I x ... x I}}$\n",
    "\n",
    "$$ \\mathscr{X} \\approx \\sum_{r=1}^R \\textbf{a}_r \\circ \\textbf{b}_r \\circ \\textbf{c}_r $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
